{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eungbean/pytorch_segmentation_tutorials/blob/main/1_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-KfdCziED16"
      },
      "source": [
        "# Semantic Segmentation Demo\n",
        "\n",
        "The code for this notebook is available here\n",
        "https://github.com/eungbean/pytorch_segmentation_tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ove9B7dDESSo"
      },
      "source": [
        "### Imports and utility functions\n",
        "먼저 라이브러리를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwl3TnWEC7q"
      },
      "source": [
        "# System libs\n",
        "import os, csv\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from collections import defaultdict\n",
        "\n",
        "# Deep learning libs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import torchsummary\n",
        "\n",
        "# visualize libs\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtqihOcQkn4g"
      },
      "source": [
        "### Enabling GPU on Colab\n",
        "GPU를 활성화 해 줍니다.\n",
        "먼저 ```런타임```-```런타임 유형변경``` 메뉴에서 'GPU'를 선택하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ2a4TN8knRJ"
      },
      "source": [
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4LBBHJdza1P"
      },
      "source": [
        "Github에서 코드를 복사해옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd78amiGkgcL"
      },
      "source": [
        "if not os.path.exists(\"helper.py\"):\n",
        "  if not os.path.exists(\"pytorch_segmentation_tutorials\"):\n",
        "    !git clone https://github.com/eungbean/pytorch_segmentation_tutorials.git\n",
        "  %cd pytorch_segmentation_tutorials\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UfZNcA1zeTq"
      },
      "source": [
        "## Data\n",
        "학습과 테스트에 사용될 데이터를 준비합니다.  \n",
        "이 노트북에서는 대용량의 데이터셋을 사용하기가 어렵기 때문에,\n",
        "Synthesize Data를 사용하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJBfdT1VZzAX"
      },
      "source": [
        "import helper\n",
        "import simulation\n",
        "\n",
        "# Generate some random images\n",
        "input_images, target_masks = simulation.generate_random_data(192, 192, count=3)\n",
        "\n",
        "print(f\"Input images: shape: {input_images.shape} | min: {input_images.min()}   | max: {input_images.max()}\")\n",
        "print(f\"Target masks: shape: {target_masks.shape} | min: {target_masks.min()} | max: {target_masks.max()}\")\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]\n",
        "\n",
        "# Left: Input image, Right: Target mask (Ground-truth)\n",
        "helper.plot_side_by_side([input_images_rgb, target_masks_rgb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sD9qniykug0"
      },
      "source": [
        "## Define Datamodule\n",
        "\n",
        "![](https://www.oreilly.com/library/view/deep-learning-with/9781789534092/assets/e03c0f94-a8ed-42fe-96a0-1eb2956445be.png)\n",
        "\n",
        "Pytorch는 데이터를 받기 위해,   \n",
        "```데이터 -> Dataset -> Dataloader``` 파이프라인을 가집니다.\n",
        "\n",
        "* ```Dataloader```: batch, train/val/test등에 따라 필요한 만큼 Dataset에 데이터를 요청.\n",
        "* ```Dataset```: 요청에 따라 파일로부터 데이터 파일을 읽어오는 역할.\n",
        "* ```Data```: 저장된 데이터 파일."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWczgP6_lGSJ"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "class SimDataset(Dataset):\n",
        "  def __init__(self, count, transform=None):\n",
        "    self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.input_images[idx]\n",
        "    mask = self.target_masks[idx]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return [image, mask]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn9GxEyMz422"
      },
      "source": [
        "Image Augmentation을 위한 파이프라인을 작성합니다.   \n",
        "* 유용한 라이브러리로 [albumentations](https://github.com/albumentations-team/albumentations)를 많이 사용합니다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEMiyS52pb8c"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDPEBKjA0MfG"
      },
      "source": [
        "학습에 사용될 데이터셋을 생성합니다.   \n",
        "(시간이 좀 걸립니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZspNWJ60JT5"
      },
      "source": [
        "train_set = SimDataset(2000, transform = transform)\n",
        "val_set = SimDataset(200, transform = transform)\n",
        "test_set = SimDataset(3, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFoCnHf9qRYo"
      },
      "source": [
        "image_datasets = {'train': train_set, 'val': val_set, 'test': test_set}\n",
        "\n",
        "# Train할 때 한 iteration당 이미지 수\n",
        "batch_size = 25\n",
        "\n",
        "# Dataloader 정의\n",
        "dataloaders = {\n",
        "  'train': DataLoader(train_set, batch_size=25, shuffle=True, num_workers=0),\n",
        "  'val': DataLoader(val_set, batch_size=25, shuffle=True, num_workers=0),\n",
        "  'test': DataLoader(test_set, batch_size=3, shuffle=False, num_workers=0)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bax_kEqsigbq"
      },
      "source": [
        "import torchvision.utils\n",
        "\n",
        "# 데이터는 Train을 위해 Normalize 된 후 Torch.tensor형태로 준비되므로 \n",
        "# 시각화하기 위해 원래대로 되돌려야 합니다.\n",
        "def reverse_transform(inp):\n",
        "  inp = inp.numpy().transpose((1, 2, 0)) # 이미지의 차원을 C,H,W 에서 H,W,C로 바꾸어 줍니다.\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  inp = std * inp + mean\n",
        "  inp = np.clip(inp, 0, 1)\n",
        "  inp = (inp * 255).astype(np.uint8)\n",
        "  return inp\n",
        "\n",
        "# 데이터로더로부터 직접 데이터를 꺼내고 싶으면 다음과 같이 사용합니다.\n",
        "inputs, masks = next(iter(dataloaders['train']))\n",
        "\n",
        "print(f\"Input shape : {inputs.shape}\")\n",
        "print(f\"Mask shape: {masks.shape}\")\n",
        "plt.imshow(reverse_transform(inputs[3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vje3ON1sEcuK"
      },
      "source": [
        "## Define the segmentation model\n",
        "\n",
        "![](https://theaisummer.com/static/3995761ad87f8909f5dec5925d182e80/4ff83/The-3D-Unet-model.png)\n",
        "\n",
        "> 그림 가장 아래쪽 channel의 수는 256이 아니라 512입니다.\n",
        "\n",
        "본격적으로 학습에 사용될 U-Net 모델을 정의합니다.\n",
        "\n",
        "### 1. ```Double_conv```\n",
        "\n",
        "```python\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )   \n",
        "```\n",
        "\n",
        "공통적으로 반복하여 사용되는 2번의 conv가 반복되는 블록입니다. ```Conv-ReLU-Conv-ReLU```의 구조를 가지는 블록입니다. 함수로 미리 정의했습니다.\n",
        "\n",
        "각 블록의 ```input 채널의 수```와 ```output 채널의 수```를 변수로 받습니다.\n",
        "\n",
        "\n",
        "### 2. U-Net\n",
        "\n",
        "> #### ```def __init__```  \n",
        "\n",
        "* 이곳에서 클래스에서 사용될 여러가지 변수를 정의합니다.   \n",
        "* 기본적인 구조는 미리 정의해드렸습니다.  \n",
        "* ```--``` 로 비워져있는 Channel number를 채워주세요.   \n",
        "\n",
        "* ```dconv_down```은 Encoder에 사용됩니다. \n",
        "* ```dconv_up```은 Decoder에 사용됩니다.\n",
        "채널의 수를 정의할 때, concat이 되는 것에 유의해주세요.  \n",
        "\n",
        "> #### ```def forward``` \n",
        "\n",
        "* 이곳에서는 네트워크를 정의합니다.  \n",
        "위 네트워크 그림을 참고해서, 모델을 만들어주세요.\n",
        "\n",
        "* Encoder와 Decoder의 첫 블락은 미리 정의해드렸습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZmvaH4wEaSp"
      },
      "source": [
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )   \n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_class):\n",
        "\n",
        "        super().__init__()\n",
        "        self.dconv_down1 = double_conv(--, --)\n",
        "        self.dconv_down2 = double_conv(--, --)\n",
        "        self.dconv_down3 = double_conv(--, --)\n",
        "        self.dconv_down4 = double_conv(--, --)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up3 = double_conv(--, --)\n",
        "        self.dconv_up2 = double_conv(--, --)\n",
        "        self.dconv_up1 = double_conv(--, --)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(--, n_class, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        ## Encoder\n",
        "        # Layer 1: input_channel=3, output_channel = 64\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        # Layer 2: input_channel=64, output_channel = 128\n",
        "        conv2 = \n",
        "        x = \n",
        "        \n",
        "        # Layer 3: input_channel=128, output_channel = 256\n",
        "        conv3 = \n",
        "        x = \n",
        "        \n",
        "        # Layer 4: input_channel=256, output_channel = 512\n",
        "        x = \n",
        "        \n",
        "        ## Decoder\n",
        "        # Layer 3\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        x = self.dconv_up3(x)\n",
        "\n",
        "        # Layer 2\n",
        "        ..\n",
        "        \n",
        "        # Layer 1\n",
        "        ..\n",
        "        \n",
        "        # Out head\n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJnef5UD78KB"
      },
      "source": [
        "클래스로 정의된 U-Net을 객체화해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0jX7CaNZRr1"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_class=6)\n",
        "model = model.to(device)\n",
        "\n",
        "# check keras-like model summary using torchsummary\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P4epc1XrrD2"
      },
      "source": [
        "## Define the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QXcVLGi8H46"
      },
      "source": [
        "학습에 사용될 Loss를 정합니다.   \n",
        "Loss는 BCE, Dice를 함께 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0MpWVNZrqRa"
      },
      "source": [
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()\n",
        "\n",
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    pred = torch.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC8u_ruZlRwL"
      },
      "source": [
        "## Define the main training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqGVoGur8QiF"
      },
      "source": [
        "Train을 하기 위한 루프를 정의합니다.     \n",
        "def train_model 함수를 상세히 보면서 하나하나 따라가보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o2K-XJAym49"
      },
      "source": [
        "def test_and_vis(model, dataloaders):\n",
        "    # Get the first batch\n",
        "    model.eval()\n",
        "    inputs, labels = next(iter(dataloaders['test']))\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # predict\n",
        "    preds = model(inputs)\n",
        "    preds = torch.sigmoid(preds)\n",
        "    preds = preds.data.cpu().numpy()\n",
        "\n",
        "    # Change channel-order and make 3 channels for matplot\n",
        "    input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
        "    # Map each channel (i.e. class) to each color\n",
        "    target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
        "    pred_rgb = [helper.masks_to_colorimg(x) for x in preds]\n",
        "\n",
        "    helper.plot_side_by_side([input_images_rgb[0], target_masks_rgb[0], pred_rgb[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvXtoMY4aEMz"
      },
      "source": [
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    \n",
        "    # 학습을 시작하기 전, 초기화를 해줍니다.\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # 각 epoch은 training and validation phase가 존재합니다.\n",
        "        for phase in ['train', 'val']:\n",
        "            # Train Phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # model을 training mode로 설정합니다.\n",
        "                scheduler.step()\n",
        "            else:\n",
        "                model.eval()   # 을model to evaluate mode로 설정합니다.\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            # 본격적인 학습이 시작됩니다.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "              # 각 데이터를 불러온 후 GPU로 이동해야 합니다.\n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "              # gradient를 0으로 초기화합니다.\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # training phase 때만 history를 추적합니다.\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(inputs)\n",
        "                  loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                  # training phase 때만 backward + optimize\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "              epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "            \n",
        "            # model을 deep copy 합니다.\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(\"saving best model\")\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # best model weights를 load 합니다.\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qCcd5ofgplf"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0wleiP4gpwb"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "num_class = 6\n",
        "\n",
        "model = UNet(num_class).to(device)\n",
        "\n",
        "# 모든 parameter들이 Optimize되는걸 관측합니다.\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Learning Rate를 스케줄링해주는 스케줄러입니다. (학습초반에는 크게, 점점 작게.)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
        "\n",
        "# Train을 시작합니다.\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqEiwCvPFAQY"
      },
      "source": [
        "## Run the Model\n",
        "Training 후 학습된 모델을 이용해서 prediction을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kU7j7_eio7C"
      },
      "source": [
        "import math\n",
        "\n",
        "model.eval()   # Set model to the evaluation mode\n",
        "\n",
        "# Get the first batch\n",
        "inputs, labels = next(iter(dataloaders['test']))\n",
        "inputs, labels = inputs.to(device),labels.to(device) \n",
        "\n",
        "# Predict\n",
        "pred = model(inputs)\n",
        "# The loss functions include the sigmoid function.\n",
        "pred = torch.sigmoid(pred)\n",
        "pred = pred.data.cpu().numpy()\n",
        "\n",
        "# Change channel-order and make 3 channels for matplot\n",
        "input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
        "\n",
        "# Map each channel (i.e. class) to each color\n",
        "target_masks_rgb = [helper.masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
        "pred_rgb = [helper.masks_to_colorimg(x) for x in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPdMjoBtw8Le"
      },
      "source": [
        "helper.plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_RZj9hq9x8r"
      },
      "source": [
        "> # 수고하셨습니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zedwFL4qOrFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}